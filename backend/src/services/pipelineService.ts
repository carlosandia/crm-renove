import { supabase } from '../config/supabase';
import supabaseAdmin from './supabase-admin';
import { CadenceService } from './cadenceService'; // ‚úÖ CORRE√á√ÉO: Importar CadenceService para delegar opera√ß√µes de cad√™ncia

export interface Pipeline {
  id: string;
  name: string;
  description: string;
  tenant_id: string;
  created_by: string;
  created_at: string;
  updated_at: string;
  pipeline_members?: any[];
  pipeline_stages?: any[];
  pipeline_custom_fields?: any[];
}

export interface CreatePipelineData {
  name: string;
  description?: string;
  tenant_id: string;
  created_by: string;
  member_ids?: string[];
}

export interface UpdatePipelineData {
  name?: string;
  description?: string;
  qualification_rules?: any; // JSONB data for MQL/SQL qualification rules
  cadence_configs?: any[]; // Array of cadence configurations
  outcome_reasons?: any[]; // Array of pipeline outcome reasons (win/loss motives)
  stages?: any[]; // ‚úÖ NOVO: Array of pipeline stages (custom stages only)
}

export interface PipelineNameValidation {
  is_valid: boolean;
  error?: string;
  suggestion?: string;
  similar_names?: string[];
}

export class PipelineService {
  static async validatePipelineName(
    name: string, 
    tenantId: string, 
    pipelineId?: string
  ): Promise<PipelineNameValidation> {
    try {
      console.log('üîç [PipelineService] Validando nome de pipeline:', {
        name,
        tenantId,
        pipelineId: pipelineId || 'novo'
      });

      // ‚úÖ TENTAR FUN√á√ÉO POSTGRESQL PRIMEIRO (tipos corretos baseados na verifica√ß√£o)
      console.log('üîÑ [PipelineService] Chamando fun√ß√£o RPC validate_pipeline_name_unique com:', {
        p_name: name.trim(),
        p_tenant_id: tenantId,
        p_pipeline_id: pipelineId || null
      });

      const { data, error } = await supabase.rpc('validate_pipeline_name_unique', {
        p_name: name.trim(),
        p_tenant_id: tenantId, // TEXT - correto conforme verifica√ß√£o
        p_pipeline_id: pipelineId || null // UUID - ser√° convertido automaticamente
      });

      if (error) {
        console.warn('‚ö†Ô∏è [PipelineService] Fun√ß√£o PostgreSQL falhou, usando fallback:', {
          error: error.message,
          code: error.code,
          details: error.details,
          hint: error.hint
        });
        throw new Error('FALLBACK_NEEDED');
      }

      console.log('‚úÖ [PipelineService] Valida√ß√£o PostgreSQL conclu√≠da:', {
        data,
        is_valid: data?.is_valid,
        has_error: !!data?.error
      });

      // ‚úÖ BUSCAR PIPELINES SIMILARES MANUALMENTE
      const { data: similarPipelines } = await supabase
        .from('pipelines')
        .select('name')
        .eq('tenant_id', tenantId)
        .ilike('name', `%${name.trim()}%`)
        .limit(3);

      return {
        is_valid: data?.is_valid || false,
        error: data?.error || undefined,
        suggestion: data?.suggestion || undefined,
        similar_names: similarPipelines?.map(p => p.name) || []
      };

    } catch (error) {
      console.error('‚ùå [PipelineService] Erro cr√≠tico na valida√ß√£o, usando fallback:', {
        error: error.message,
        name,
        tenantId,
        pipelineId: pipelineId || 'novo'
      });
      
      // ‚úÖ CORRE√á√ÉO CR√çTICA: Excluir pipeline atual da valida√ß√£o em fallback mode
      let query = supabase
        .from('pipelines')
        .select('name, id')
        .eq('tenant_id', tenantId)
        .ilike('name', name.trim())
        .eq('is_active', true);

      // Se √© uma edi√ß√£o, excluir a pipeline atual da valida√ß√£o
      if (pipelineId) {
        console.log('üîç [PipelineService] Modo edi√ß√£o: excluindo pipeline atual da valida√ß√£o:', pipelineId);
        query = query.neq('id', pipelineId);
      }

      const { data: existingPipelines, error: fallbackError } = await query;

      if (fallbackError) {
        console.error('‚ùå [PipelineService] Erro na valida√ß√£o fallback:', fallbackError);
        throw new Error(`Erro na valida√ß√£o fallback: ${fallbackError.message}`);
      }

      console.log('üîç [PipelineService] Pipelines existentes encontradas:', {
        count: existingPipelines?.length || 0,
        pipelines: existingPipelines?.map(p => ({ name: p.name, id: p.id })) || [],
        searchingFor: name.trim().toLowerCase()
      });

      const hasConflict = existingPipelines?.some(p => 
        p.name.toLowerCase().trim() === name.toLowerCase().trim()
      ) || false;

      console.log('üîç [PipelineService] Resultado da valida√ß√£o fallback:', {
        hasConflict,
        is_valid: !hasConflict,
        conflictingPipelines: existingPipelines?.filter(p => 
          p.name.toLowerCase().trim() === name.toLowerCase().trim()
        ).map(p => ({ name: p.name, id: p.id })) || []
      });

      return {
        is_valid: !hasConflict,
        error: hasConflict ? 'J√° existe uma pipeline com este nome' : undefined,
        suggestion: hasConflict ? `${name} (2)` : undefined,
        similar_names: existingPipelines?.map(p => p.name) || []
      };
    }
  }

  static async getPipelinesByTenant(tenantId: string): Promise<Pipeline[]> {
    const { data: pipelines, error: pipelinesError } = await supabase
      .from('pipelines')
      .select('*')
      .eq('tenant_id', tenantId)
      .order('created_at', { ascending: false });

    if (pipelinesError) {
      throw new Error(`Erro ao buscar pipelines: ${pipelinesError.message}`);
    }

    if (!pipelines || pipelines.length === 0) {
      return [];
    }

    const pipelinesWithDetails = await Promise.all(
      pipelines.map(async (pipeline) => {
        const { data: pipelineMembers } = await supabase
          .from('pipeline_members')
          .select('*')
          .eq('pipeline_id', pipeline.id);

        const membersWithUserData = await Promise.all(
          (pipelineMembers || []).map(async (pm) => {
            const { data: userData } = await supabase
              .from('users')
              .select('id, first_name, last_name, email')
              .eq('id', pm.member_id)
              .single();

            return {
              ...pm,
              member: userData
            };
          })
        );

        const { data: stages } = await supabase
          .from('pipeline_stages')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('order_index');

        const { data: customFields } = await supabase
          .from('pipeline_custom_fields')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('field_order', { ascending: true });

        return {
          ...pipeline,
          pipeline_members: membersWithUserData || [],
          pipeline_stages: stages || [],
          pipeline_custom_fields: customFields || []
        };
      })
    );

    return pipelinesWithDetails;
  }

  static async getPipelineById(id: string): Promise<Pipeline | null> {
    // üîß CORRE√á√ÉO: Buscar pipeline b√°sico primeiro
    const { data: pipeline, error } = await supabase
      .from('pipelines')
      .select('*')
      .eq('id', id)
      .single();

    if (error) {
      if (error.code === 'PGRST116') return null;
      throw new Error(`Erro ao buscar pipeline: ${error.message}`);
    }

    // üîß CORRE√á√ÉO: Buscar relacionamentos separadamente para evitar erro de schema cache
    const { data: pipelineMembers } = await supabase
      .from('pipeline_members')
      .select('*')
      .eq('pipeline_id', id);

    const { data: pipelineStages } = await supabase
      .from('pipeline_stages')
      .select('*')
      .eq('pipeline_id', id)
      .order('order_index');

    // üîß CORRE√á√ÉO: Buscar campos customizados da pipeline
    const { data: pipelineCustomFields } = await supabase
      .from('pipeline_custom_fields')
      .select('*')
      .eq('pipeline_id', id)
      .order('field_order');

    // Buscar dados dos membros se houver
    const membersWithUserData = await Promise.all(
      (pipelineMembers || []).map(async (pm) => {
        const { data: userData } = await supabase
          .from('users')
          .select('id, first_name, last_name, email')
          .eq('id', pm.member_id)
          .single();

        return {
          ...pm,
          member: userData
        };
      })
    );

    return {
      ...pipeline,
      pipeline_members: membersWithUserData,
      pipeline_stages: pipelineStages || [],
      pipeline_custom_fields: pipelineCustomFields || []
    };
  }

  static async createPipeline(data: CreatePipelineData): Promise<Pipeline> {
    const { member_ids, ...pipelineData } = data;

    console.log('üîç [PipelineService] Validando nome antes de criar pipeline...');
    const validation = await this.validatePipelineName(
      pipelineData.name,
      pipelineData.tenant_id
    );

    if (!validation.is_valid) {
      const errorMessage = `${validation.error}${validation.suggestion ? ` Sugest√£o: "${validation.suggestion}"` : ''}`;
      console.error('‚ùå [PipelineService] Valida√ß√£o falhou:', errorMessage);
      throw new Error(errorMessage);
    }

    console.log('‚úÖ [PipelineService] Nome validado, criando pipeline...');

    const { data: pipeline, error: pipelineError } = await supabase
      .from('pipelines')
      .insert(pipelineData)
      .select()
      .single();

    if (pipelineError) {
      if (pipelineError.code === '23505' && pipelineError.message.includes('idx_pipelines_unique_name_per_tenant')) {
        throw new Error(`J√° existe uma pipeline com o nome "${pipelineData.name}" nesta empresa. Escolha um nome diferente.`);
      }
      throw new Error(`Erro ao criar pipeline: ${pipelineError.message}`);
    }

    if (member_ids && member_ids.length > 0) {
      const memberInserts = member_ids.map(member_id => ({
        pipeline_id: pipeline.id,
        member_id
      }));

      const { error: membersError } = await supabase
        .from('pipeline_members')
        .insert(memberInserts);

      if (membersError) {
        console.warn('‚ö†Ô∏è [PipelineService] Erro ao adicionar membros:', membersError);
      }
    }

    // ‚úÖ NOVO: Criar campos sistema obrigat√≥rios (nome, email, telefone)
    const systemFields = [
      {
        pipeline_id: pipeline.id,
        field_name: 'nome_lead',
        field_label: 'Nome do Lead',
        field_type: 'text',
        is_required: true,
        field_order: 1,
        placeholder: 'Digite o nome do lead',
        show_in_card: true,
        tenant_id: pipeline.tenant_id
      },
      {
        pipeline_id: pipeline.id,
        field_name: 'email',
        field_label: 'E-mail',
        field_type: 'email',
        is_required: true,
        field_order: 2,
        placeholder: 'exemplo@email.com',
        show_in_card: true,
        tenant_id: pipeline.tenant_id
      },
      {
        pipeline_id: pipeline.id,
        field_name: 'telefone',
        field_label: 'Telefone',
        field_type: 'phone',
        is_required: true,
        field_order: 3,
        placeholder: '(11) 99999-9999',
        show_in_card: true,
        tenant_id: pipeline.tenant_id
      }
    ];

    const { error: fieldsError } = await supabase
      .from('pipeline_custom_fields')
      .insert(systemFields);

    if (fieldsError) {
      console.warn('‚ö†Ô∏è [PipelineService] Erro ao criar campos sistema:', fieldsError);
    } else {
      console.log('‚úÖ [PipelineService] Campos sistema criados com sucesso');
    }

    console.log('‚úÖ [PipelineService] Pipeline criada com sucesso:', {
      id: pipeline.id,
      name: pipeline.name,
      tenant_id: pipeline.tenant_id
    });

    return pipeline;
  }

  static async updatePipeline(id: string, data: UpdatePipelineData): Promise<Pipeline> {
    console.log('üîç [PipelineService] Iniciando atualiza√ß√£o da pipeline:', {
      id: id.substring(0, 8),
      hasName: !!data.name,
      hasDescription: !!data.description,
      hasQualificationRules: !!data.qualification_rules,
      hasCadenceConfigs: !!data.cadence_configs?.length,
      hasOutcomeReasons: !!data.outcome_reasons?.length
    });

    // Buscar pipeline atual para valida√ß√µes
    const currentPipeline = await this.getPipelineById(id);
    if (!currentPipeline) {
      throw new Error('Pipeline n√£o encontrada');
    }

    // Validar nome se fornecido
    if (data.name) {
      console.log('üîç [PipelineService] Validando novo nome para edi√ß√£o...');
      
      const validation = await this.validatePipelineName(
        data.name,
        currentPipeline.tenant_id,
        id
      );

      if (!validation.is_valid) {
        const errorMessage = `${validation.error}${validation.suggestion ? ` Sugest√£o: "${validation.suggestion}"` : ''}`;
        console.error('‚ùå [PipelineService] Valida√ß√£o de edi√ß√£o falhou:', errorMessage);
        throw new Error(errorMessage);
      }

      console.log('‚úÖ [PipelineService] Nome validado para edi√ß√£o');
    }

    // ‚úÖ NOVA FUNCIONALIDADE: Preparar dados para atualiza√ß√£o da pipeline principal
    const pipelineUpdateData: any = {};
    if (data.name !== undefined) pipelineUpdateData.name = data.name;
    if (data.description !== undefined) pipelineUpdateData.description = data.description;
    if (data.qualification_rules !== undefined) pipelineUpdateData.qualification_rules = data.qualification_rules;

    // Atualizar pipeline principal (name, description, qualification_rules)
    let updatedPipeline = currentPipeline;
    if (Object.keys(pipelineUpdateData).length > 0) {
      console.log('üîÑ [PipelineService] Atualizando dados principais da pipeline...');
      
      const { data: pipeline, error } = await supabase
        .from('pipelines')
        .update(pipelineUpdateData)
        .eq('id', id)
        .select()
        .single();

      if (error) {
        if (error.code === '23505' && error.message.includes('idx_pipelines_unique_name_per_tenant')) {
          throw new Error(`J√° existe uma pipeline com o nome "${data.name}" nesta empresa. Escolha um nome diferente.`);
        }
        throw new Error(`Erro ao atualizar pipeline: ${error.message}`);
      }

      updatedPipeline = pipeline;
      console.log('‚úÖ [PipelineService] Dados principais atualizados');
    }

    // ‚úÖ CORRE√á√ÉO: Delegar opera√ß√µes de cad√™ncia para CadenceService (evita erro 500)
    if (data.cadence_configs !== undefined) {
      console.log('üîÑ [PipelineService] Delegando configura√ß√µes de cad√™ncia para CadenceService...');
      
      try {
        // ‚úÖ CORRE√á√ÉO: Usar CadenceService.saveCadenceConfig() que tem l√≥gica robusta
        // Este m√©todo usa service role e trata adequadamente RLS e conflitos de dados
        const cadenceResult = await CadenceService.saveCadenceConfig(
          id, // pipeline_id
          data.cadence_configs, // configura√ß√µes com tasks
          currentPipeline.tenant_id,
          'pipeline_update_operation' // created_by identificando a origem
        );

        if (cadenceResult.success) {
          console.log('‚úÖ [PipelineService] Cad√™ncias salvas via CadenceService:', {
            pipeline_id: id.substring(0, 8),
            configs_count: data.cadence_configs.length,
            message: cadenceResult.message
          });
        } else {
          // ‚úÖ DEGRADA√á√ÉO GRACIOSA: Log do erro mas n√£o falha completamente
          console.warn('‚ö†Ô∏è [PipelineService] Cad√™ncias falharam mas pipeline foi salva:', {
            pipeline_id: id.substring(0, 8),
            error: cadenceResult.message,
            degraded_mode: true
          });
          // N√£o throw - permite que pipeline principal seja salva mesmo com falha nas cad√™ncias
        }
      } catch (cadenceError: any) {
        // ‚úÖ DEGRADA√á√ÉO GRACIOSA: Log do erro mas n√£o falha completamente
        console.error('‚ùå [PipelineService] Erro cr√≠tico em cad√™ncias (modo degradado):', {
          pipeline_id: id.substring(0, 8),
          error: cadenceError.message,
          stack: cadenceError.stack?.split('\n').slice(0, 3),
          degraded_mode: true
        });
        // N√£o throw - permite que dados principais da pipeline sejam salvos
      }
    }

    // ‚úÖ NOVA FUNCIONALIDADE: Atualizar outcome_reasons se fornecidas
    if (data.outcome_reasons !== undefined) {
      console.log('üîÑ [PipelineService] Atualizando motivos de resultado...');
      
      try {
        // Remover motivos existentes
        const { error: deleteError } = await supabase
          .from('pipeline_outcome_reasons')
          .delete()
          .eq('pipeline_id', id);

        if (deleteError) {
          console.warn('‚ö†Ô∏è [PipelineService] Aviso ao remover motivos existentes:', deleteError.message);
        }

        // Inserir novos motivos se houver
        if (data.outcome_reasons.length > 0) {
          const reasonsData = data.outcome_reasons.map(reason => ({
            ...reason,
            pipeline_id: id,
            tenant_id: currentPipeline.tenant_id
          }));

          const { error: insertError } = await supabase
            .from('pipeline_outcome_reasons')
            .insert(reasonsData);

          if (insertError) {
            console.error('‚ùå [PipelineService] Erro ao inserir motivos:', insertError.message);
            throw new Error(`Erro ao salvar motivos de resultado: ${insertError.message}`);
          }

          console.log('‚úÖ [PipelineService] Motivos de resultado atualizados:', data.outcome_reasons.length);
        } else {
          console.log('‚úÖ [PipelineService] Motivos removidos (array vazio)');
        }
      } catch (reasonsError: any) {
        console.error('‚ùå [PipelineService] Erro cr√≠tico ao atualizar motivos:', reasonsError.message);
        throw new Error(`Erro ao atualizar motivos: ${reasonsError.message}`);
      }
    }

    // ‚úÖ NOVA FUNCIONALIDADE: Atualizar pipeline_stages se fornecidas
    if (data.stages !== undefined) {
      console.log('üîÑ [PipelineService] Atualizando etapas da pipeline...');
      
      try {
        // ‚úÖ NOVA ABORDAGEM: Atualizar order_index das stages existentes (n√£o-destrutivo)
        console.log('üîÑ [PipelineService] Atualizando ordem das etapas (n√£o-destrutivo)...');
        
        if (data.stages.length > 0) {
          // ‚úÖ FILTRAR: Apenas stages customizadas (n√£o do sistema)
          const customStages = data.stages.filter(stage => !stage.is_system_stage);
          
          if (customStages.length > 0) {
            console.log('üìù [PipelineService] Atualizando order_index de', customStages.length, 'etapas customizadas');
            
            // Atualizar cada stage individualmente com sua nova order_index
            for (const stage of customStages) {
              console.log(`üîÑ Atualizando etapa "${stage.name}" para order_index: ${stage.order_index}`);
              
              const { error: updateError } = await supabase
                .from('pipeline_stages')
                .update({ 
                  order_index: stage.order_index,
                  color: stage.color || '#3B82F6' // Tamb√©m atualizar cor se fornecida
                })
                .eq('pipeline_id', id)
                .eq('name', stage.name)
                .eq('is_system_stage', false);

              if (updateError) {
                console.error(`‚ùå [PipelineService] Erro ao atualizar etapa "${stage.name}":`, updateError.message);
                throw new Error(`Erro ao atualizar etapa "${stage.name}": ${updateError.message}`);
              }
            }

            console.log('‚úÖ [PipelineService] Ordem das etapas atualizada com sucesso');
          } else {
            console.log('‚úÖ [PipelineService] Apenas stages do sistema fornecidas, nenhuma atualiza√ß√£o necess√°ria');
          }
        } else {
          console.log('‚ö†Ô∏è [PipelineService] Nenhuma etapa fornecida para atualiza√ß√£o');
        }
      } catch (stagesError: any) {
        console.error('‚ùå [PipelineService] Erro cr√≠tico ao atualizar stages:', stagesError.message);
        throw new Error(`Erro ao atualizar etapas: ${stagesError.message}`);
      }
    }

    // ‚úÖ VALIDA√á√ÉO DE CONSIST√äNCIA: Verificar se cadence_configs e task_instances est√£o sincronizados
    if (data.cadence_configs !== undefined) {
      console.log('üîç [PipelineService] Validando consist√™ncia cadence_configs vs task_instances...');
      try {
        await this.validateCadenceConsistency(id, currentPipeline.tenant_id);
      } catch (validationError: any) {
        console.warn('‚ö†Ô∏è [PipelineService] Aviso de consist√™ncia (n√£o cr√≠tico):', {
          pipeline_id: id.substring(0, 8), 
          validation_error: validationError.message
        });
        // N√£o falhar por problemas de valida√ß√£o - apenas log
      }
    }

    console.log('‚úÖ [PipelineService] Pipeline atualizada com sucesso:', {
      id: updatedPipeline.id,
      name: updatedPipeline.name,
      hasQualificationRules: !!(updatedPipeline as any).qualification_rules,
      updatedCadences: data.cadence_configs !== undefined,
      updatedReasons: data.outcome_reasons !== undefined,
      updatedStages: data.stages !== undefined
    });

    return updatedPipeline;
  }

  /**
   * ‚úÖ NOVO: Validar consist√™ncia entre cadence_configs e task_instances
   * Prevenir inconsist√™ncias futuras entre configura√ß√µes e inst√¢ncias
   */
  static async validateCadenceConsistency(pipelineId: string, tenantId: string): Promise<void> {
    try {
      console.log('üîç [PipelineService] Iniciando valida√ß√£o de consist√™ncia...', {
        pipeline_id: pipelineId.substring(0, 8),
        tenant_id: tenantId.substring(0, 8)
      });

      // Verificar se h√° cadence_configs
      const { data: configs, error: configsError } = await supabase
        .from('cadence_configs')
        .select('id, stage_name, tasks')
        .eq('pipeline_id', pipelineId)
        .eq('tenant_id', tenantId);

      if (configsError) {
        throw new Error(`Erro ao buscar cadence_configs: ${configsError.message}`);
      }

      // Verificar se h√° task_instances
      const { data: instances, error: instancesError } = await supabase
        .from('cadence_task_instances')
        .select('id, stage_id')
        .eq('pipeline_id', pipelineId)
        .eq('tenant_id', tenantId)
        .limit(5); // Apenas uma amostra para verificar exist√™ncia

      if (instancesError) {
        throw new Error(`Erro ao buscar task_instances: ${instancesError.message}`);
      }

      const hasConfigs = configs && configs.length > 0;
      const hasInstances = instances && instances.length > 0;

      console.log('üìä [PipelineService] Resultado da valida√ß√£o:', {
        pipeline_id: pipelineId.substring(0, 8),
        has_configs: hasConfigs,
        configs_count: configs?.length || 0,
        has_instances: hasInstances,
        instances_sample: instances?.length || 0
      });

      // ‚úÖ CASOS V√ÅLIDOS:
      // 1. Ambos existem (normal)
      // 2. Nenhum existe (pipeline nova sem cad√™ncias)
      if ((hasConfigs && hasInstances) || (!hasConfigs && !hasInstances)) {
        console.log('‚úÖ [PipelineService] Consist√™ncia validada - estado normal');
        return;
      }

      // ‚ö†Ô∏è CASOS DE INCONSIST√äNCIA:
      if (hasInstances && !hasConfigs) {
        console.warn('‚ö†Ô∏è [PipelineService] Inconsist√™ncia detectada: task_instances sem cadence_configs');
        // Este era o problema do usu√°rio - j√° resolvido com a migra√ß√£o
      } else if (hasConfigs && !hasInstances) {
        console.warn('‚ö†Ô∏è [PipelineService] Aviso: cadence_configs sem task_instances (normal para pipelines novas)');
      }

    } catch (error: any) {
      console.error('‚ùå [PipelineService] Erro na valida√ß√£o de consist√™ncia:', error.message);
      throw error;
    }
  }

  static async deletePipeline(id: string): Promise<void> {
    const { error } = await supabase
      .from('pipelines')
      .delete()
      .eq('id', id);

    if (error) {
      throw new Error(`Erro ao excluir pipeline: ${error.message}`);
    }
  }

  static async getPipelinesByMember(memberId: string): Promise<Pipeline[]> {
    const { data: pipelineMembers, error: membersError } = await supabase
      .from('pipeline_members')
      .select('pipeline_id')
      .eq('member_id', memberId);

    if (membersError) {
      throw new Error(`Erro ao buscar pipeline_members: ${membersError.message}`);
    }

    if (!pipelineMembers || pipelineMembers.length === 0) {
      return [];
    }

    const pipelineIds = pipelineMembers.map(pm => pm.pipeline_id);

    const { data: pipelines, error: pipelinesError } = await supabase
      .from('pipelines')
      .select('*')
      .in('id', pipelineIds)
      .order('created_at', { ascending: false });

    if (pipelinesError) {
      throw new Error(`Erro ao buscar pipelines: ${pipelinesError.message}`);
    }

    if (!pipelines || pipelines.length === 0) {
      return [];
    }

    const pipelinesWithDetails = await Promise.all(
      pipelines.map(async (pipeline) => {
        const { data: stages } = await supabase
          .from('pipeline_stages')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('order_index');

        const { data: customFields } = await supabase
          .from('pipeline_custom_fields')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('field_order');

        return {
          ...pipeline,
          pipeline_stages: stages || [],
          pipeline_custom_fields: customFields || []
        };
      })
    );

    return pipelinesWithDetails;
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Arquivar pipeline (soft delete)
  static async archivePipeline(pipelineId: string, tenantId: string): Promise<void> {
    console.log('üìÅ [PipelineService] Arquivando pipeline:', { pipelineId, tenantId });

    // Verificar se pipeline existe e pertence ao tenant
    const { data: pipeline, error: checkError } = await supabase
      .from('pipelines')
      .select('id, name, is_active')
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId)
      .single();

    if (checkError || !pipeline) {
      throw new Error('Pipeline n√£o encontrada ou n√£o pertence a esta empresa');
    }

    if (!pipeline.is_active) {
      throw new Error('Pipeline j√° est√° inativa');
    }

    // Arquivar pipeline (soft delete)
    const { error: archiveError } = await supabase
      .from('pipelines')
      .update({ 
        is_archived: true,
        archived_at: new Date().toISOString(),
        is_active: false // Manter consist√™ncia com campo existente
      })
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId);

    if (archiveError) {
      console.error('‚ùå [PipelineService] Erro ao arquivar pipeline:', archiveError);
      throw new Error('Erro ao arquivar pipeline');
    }

    console.log('‚úÖ [PipelineService] Pipeline arquivada com sucesso:', pipeline.name);
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Desarquivar pipeline
  static async unarchivePipeline(pipelineId: string, tenantId: string): Promise<void> {
    console.log('üìÇ [PipelineService] Desarquivando pipeline:', { pipelineId, tenantId });

    // Verificar se pipeline existe e pertence ao tenant
    const { data: pipeline, error: checkError } = await supabase
      .from('pipelines')
      .select('id, name, is_archived, archived_at')
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId)
      .single();

    if (checkError || !pipeline) {
      console.error('‚ùå [PipelineService] Pipeline n√£o encontrada:', { pipelineId, tenantId, error: checkError });
      throw new Error('Pipeline n√£o encontrada ou n√£o pertence a esta empresa');
    }

    console.log('üîç [PipelineService] Status da pipeline:', { 
      id: pipeline.id, 
      name: pipeline.name, 
      is_archived: pipeline.is_archived, 
      archived_at: pipeline.archived_at 
    });

    // ‚úÖ CORRE√á√ÉO: Usar is_archived ao inv√©s de archived_at para valida√ß√£o
    if (!pipeline.is_archived) {
      console.warn('‚ö†Ô∏è [PipelineService] Pipeline j√° est√° ativa:', pipeline.name);
      throw new Error('Pipeline n√£o est√° arquivada');
    }

    // Desarquivar pipeline
    const { error: unarchiveError } = await supabase
      .from('pipelines')
      .update({ 
        is_archived: false,
        archived_at: null,
        is_active: true // Reativar pipeline
      })
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId);

    if (unarchiveError) {
      console.error('‚ùå [PipelineService] Erro ao desarquivar pipeline:', unarchiveError);
      throw new Error('Erro ao desarquivar pipeline');
    }

    console.log('‚úÖ [PipelineService] Pipeline desarquivada com sucesso:', pipeline.name);

    // ‚úÖ VALIDA√á√ÉO: Garantir que pipeline tenha etapas obrigat√≥rias ap√≥s desarquivamento
    try {
      console.log('üîç [PipelineService] Verificando etapas obrigat√≥rias ap√≥s desarquivamento...');
      // AIDEV-NOTE: Verifica√ß√£o simples de etapas - m√©todo ensurePipelineStages n√£o implementado ainda
      const { data: stages, error: stagesError } = await supabase
        .from('pipeline_stages')
        .select('id, name, stage_type')
        .eq('pipeline_id', pipelineId)
        .eq('tenant_id', tenantId);

      if (stagesError) {
        console.warn('‚ö†Ô∏è [PipelineService] Erro ao verificar etapas:', stagesError.message);
      } else if (!stages || stages.length === 0) {
        console.warn('‚ö†Ô∏è [PipelineService] Pipeline desarquivada sem etapas - pode precisar de configura√ß√£o');
      } else {
        console.log('‚úÖ [PipelineService] Etapas encontradas:', stages.length);
      }
    } catch (stageError: any) {
      console.warn('‚ö†Ô∏è [PipelineService] Aviso: Erro ao validar etapas obrigat√≥rias:', stageError.message);
      // N√£o lan√ßar erro aqui, pois pipeline j√° foi desarquivada com sucesso
      // O aviso permite que a opera√ß√£o continue, mas registra o problema
    }
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Listar pipelines arquivadas
  static async getArchivedPipelines(tenantId: string): Promise<Pipeline[]> {
    console.log('üìã [PipelineService] Buscando pipelines arquivadas para tenant:', tenantId);

    const { data: pipelines, error } = await supabase
      .from('pipelines')
      .select(`
        id, name, description, tenant_id, created_by, created_at, updated_at, archived_at,
        pipeline_stages (id, name, order_index, stage_type),
        pipeline_custom_fields (id, field_name, field_type, is_required)
      `)
      .eq('tenant_id', tenantId)
      .not('archived_at', 'is', null) // Apenas pipelines arquivadas
      .order('archived_at', { ascending: false }); // Mais recentemente arquivadas primeiro

    if (error) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipelines arquivadas:', error);
      throw new Error('Erro ao buscar pipelines arquivadas');
    }

    console.log('‚úÖ [PipelineService] Pipelines arquivadas encontradas:', pipelines?.length || 0);

    return pipelines || [];
  }

  // ‚úÖ FUNCIONALIDADE ATUALIZADA: Modificar getAllByTenant para excluir arquivadas por padr√£o
  static async getActivePipelines(tenantId: string): Promise<Pipeline[]> {
    console.log('üìã [PipelineService] Buscando pipelines ativas para tenant:', tenantId);

    const { data: pipelines, error } = await supabase
      .from('pipelines')
      .select(`
        id, name, description, tenant_id, created_by, created_at, updated_at, is_active,
        pipeline_stages (id, name, order_index, stage_type),
        pipeline_custom_fields (id, field_name, field_type, is_required)
      `)
      .eq('tenant_id', tenantId)
      .eq('is_active', true)
      .is('archived_at', null) // Apenas pipelines n√£o arquivadas
      .order('created_at', { ascending: false });

    if (error) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipelines ativas:', error);
      throw new Error('Erro ao buscar pipelines ativas');
    }

    console.log('‚úÖ [PipelineService] Pipelines ativas encontradas:', pipelines?.length || 0);

    return pipelines || [];
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Duplicar pipeline completa
  static async duplicatePipeline(pipelineId: string, tenantId: string, userId: string) {
    console.log('üîÑ [PipelineService] Iniciando duplica√ß√£o:', { pipelineId, tenantId, userId });

    // üîç VALIDA√á√ÉO SIMPLIFICADA: Verificar disponibilidade do supabaseAdmin
    console.log('üîç [PipelineService] Inicializando duplica√ß√£o com sistema de fallback...');

    // 1. Buscar pipeline original com todos os dados relacionados
    console.log('üîç [PipelineService] Buscando pipeline original...');
    
    // üîÑ SISTEMA DE FALLBACK OTIMIZADO - Teste de conectividade antes
    let dbClient = supabaseAdmin;
    let originalPipeline: any = null;
    let pipelineError: any = null;

    // ‚úÖ OTIMIZA√á√ÉO: Testar conectividade rapidamente primeiro
    try {
      // Teste r√°pido de conectividade (timeout 3s)
      const testQuery = await supabaseAdmin
        .from('pipelines')
        .select('id')
        .limit(1)
        .abortSignal(AbortSignal.timeout(3000));
      
      if (!testQuery.error) {
        console.log('‚úÖ [PipelineService] supabaseAdmin conectado - usando diretamente');
        dbClient = supabaseAdmin;
      } else {
        throw new Error('supabaseAdmin indispon√≠vel');
      }
    } catch (connectivityError: any) {
      console.warn('‚ö†Ô∏è [PipelineService] supabaseAdmin indispon√≠vel, usando fallback:', connectivityError.message);
      dbClient = supabase;
    }

    // Usar cliente selecionado diretamente (sem loop)
    try {
      const clientName = dbClient === supabaseAdmin ? 'supabaseAdmin' : 'supabase';
      console.log(`üîç [PipelineService] Usando ${clientName}...`);
        
      // üîß CORRE√á√ÉO: Buscar pipeline b√°sica primeiro para evitar erro de schema cache
      const pipelineResult = await dbClient
        .from('pipelines')
        .select('*')
        .eq('id', pipelineId)
        .eq('tenant_id', tenantId)
        .single();
      
      if (pipelineResult.error || !pipelineResult.data) {
        throw new Error(`Pipeline n√£o encontrada: ${pipelineResult.error?.message}`);
      }
      
      // Buscar relacionamentos separadamente para evitar erro de schema cache
      const [stagesResult, fieldsResult, membersResult, distributionResult, cadenceResult] = await Promise.all([
        dbClient.from('pipeline_stages').select('*').eq('pipeline_id', pipelineId),
        dbClient.from('pipeline_custom_fields').select('*').eq('pipeline_id', pipelineId),
        dbClient.from('pipeline_members').select('*').eq('pipeline_id', pipelineId),
        dbClient.from('pipeline_distribution_rules').select('*').eq('pipeline_id', pipelineId),
        dbClient.from('cadence_configs').select('*').eq('pipeline_id', pipelineId)
      ]);
      
      originalPipeline = {
        ...pipelineResult.data,
        pipeline_stages: stagesResult.data || [],
        pipeline_custom_fields: fieldsResult.data || [],
        pipeline_members: membersResult.data || [],
        pipeline_distribution_rules: distributionResult.data || [],
        cadence_configs: cadenceResult.data || []
      };
      
      console.log(`‚úÖ [PipelineService] Sucesso com ${clientName}`);
      
    } catch (error: any) {
      console.error(`‚ùå [PipelineService] Erro com ${dbClient === supabaseAdmin ? 'supabaseAdmin' : 'supabase'}:`, error.message);
      pipelineError = error;
      
      // ‚úÖ FALLBACK FINAL: Se o cliente principal falhou, tentar o outro
      if (dbClient === supabaseAdmin) {
        console.log('üîÑ [PipelineService] Tentando fallback para supabase...');
        dbClient = supabase;
        try {
          const pipelineResult = await dbClient
            .from('pipelines')
            .select('*')
            .eq('id', pipelineId)
            .eq('tenant_id', tenantId)
            .single();
          
          if (!pipelineResult.error && pipelineResult.data) {
            const [stagesResult, fieldsResult, membersResult, distributionResult, cadenceResult] = await Promise.all([
              dbClient.from('pipeline_stages').select('*').eq('pipeline_id', pipelineId),
              dbClient.from('pipeline_custom_fields').select('*').eq('pipeline_id', pipelineId),
              dbClient.from('pipeline_members').select('*').eq('pipeline_id', pipelineId),
              dbClient.from('pipeline_distribution_rules').select('*').eq('pipeline_id', pipelineId),
              dbClient.from('cadence_configs').select('*').eq('pipeline_id', pipelineId)
            ]);
            
            originalPipeline = {
              ...pipelineResult.data,
              pipeline_stages: stagesResult.data || [],
              pipeline_custom_fields: fieldsResult.data || [],
              pipeline_members: membersResult.data || [],
              pipeline_distribution_rules: distributionResult.data || [],
              cadence_configs: cadenceResult.data || []
            };
            
            console.log('‚úÖ [PipelineService] Fallback para supabase bem-sucedido');
            pipelineError = null;
          }
        } catch (fallbackError: any) {
          console.error('‚ùå [PipelineService] Fallback tamb√©m falhou:', fallbackError.message);
          pipelineError = fallbackError;
        }
      }
    }

    if (pipelineError || !originalPipeline) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipeline original:', pipelineError);
      throw new Error(`Pipeline n√£o encontrada ou sem permiss√£o: ${pipelineError?.message || 'Erro desconhecido'}`);
    }

    console.log('‚úÖ [PipelineService] Pipeline original encontrada:', {
      id: originalPipeline.id,
      name: originalPipeline.name,
      stages: originalPipeline.pipeline_stages?.length || 0,
      fields: originalPipeline.pipeline_custom_fields?.length || 0,
      members: originalPipeline.pipeline_members?.length || 0,
      distribution_rules: originalPipeline.pipeline_distribution_rules?.length || 0,
      cadence_configs: originalPipeline.cadence_configs?.length || 0
    });

    // 2. Gerar nome √∫nico para a c√≥pia
    const originalName = originalPipeline.name;
    let duplicateName = `${originalName} - C√≥pia`;
    
    // Verificar se j√° existe uma pipeline com este nome
    const { data: existingPipelines } = await supabaseAdmin
      .from('pipelines')
      .select('name')
      .eq('tenant_id', tenantId)
      .ilike('name', `${originalName}%`);
    
    // Se existir, encontrar pr√≥ximo n√∫mero dispon√≠vel
    if (existingPipelines && existingPipelines.length > 0) {
      const existingNames = existingPipelines.map(p => p.name);
      let counter = 2;
      
      while (existingNames.includes(duplicateName)) {
        duplicateName = `${originalName} (${counter})`;
        counter++;
      }
    }

    // 3. Criar nova pipeline
    console.log('üîÑ [PipelineService] Criando nova pipeline:', duplicateName);
    const { data: newPipeline, error: newPipelineError } = await dbClient
      .from('pipelines')
      .insert({
        name: duplicateName,
        description: `${originalPipeline.description || ''} (Duplicada)`,
        tenant_id: tenantId,
        created_by: userId,
        is_active: true,
        qualification_rules: originalPipeline.qualification_rules
      })
      .select()
      .single();
    
    console.log('üîç [PipelineService] Resultado cria√ß√£o pipeline:', { 
      success: !!newPipeline, 
      error: newPipelineError?.message,
      clientUsed: dbClient === supabaseAdmin ? 'supabaseAdmin' : 'supabase'
    });

    if (newPipelineError || !newPipeline) {
      console.error('‚ùå [PipelineService] Erro ao criar nova pipeline:', newPipelineError);
      throw new Error('Erro ao criar nova pipeline');
    }

    console.log('‚úÖ [PipelineService] Nova pipeline criada:', newPipeline.id);

    // 4. Duplicar stages
    if (originalPipeline.pipeline_stages?.length > 0) {
      const stagesData = originalPipeline.pipeline_stages.map((stage: any) => ({
        pipeline_id: newPipeline.id,
        name: stage.name,
        order_index: stage.order_index,
        stage_type: stage.stage_type,
        color: stage.color,
        is_default: stage.is_default,
        tenant_id: tenantId
      }));

      const { error: stagesError } = await dbClient
        .from('pipeline_stages')
        .insert(stagesData);

      if (stagesError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar stages:', stagesError);
        // N√£o falhar a opera√ß√£o, continuar
      } else {
        console.log('‚úÖ [PipelineService] Stages duplicadas:', stagesData.length);
      }
    }

    // 5. Duplicar custom fields
    if (originalPipeline.pipeline_custom_fields?.length > 0) {
      const fieldsData = originalPipeline.pipeline_custom_fields.map((field: any) => ({
        pipeline_id: newPipeline.id,
        field_name: field.field_name,
        field_label: field.field_label,
        field_type: field.field_type,
        field_options: field.field_options,
        is_required: field.is_required,
        field_order: field.field_order,
        placeholder: field.placeholder,
        show_in_card: field.show_in_card,
        tenant_id: tenantId
      }));

      const { error: fieldsError } = await dbClient
        .from('pipeline_custom_fields')
        .insert(fieldsData);

      if (fieldsError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar campos:', fieldsError);
      } else {
        console.log('‚úÖ [PipelineService] Campos customizados duplicados:', fieldsData.length);
      }
    }

    // 6. Duplicar members
    if (originalPipeline.pipeline_members?.length > 0) {
      const membersData = originalPipeline.pipeline_members.map((member: any) => ({
        pipeline_id: newPipeline.id,
        member_id: member.member_id  // ‚úÖ CORRE√á√ÉO: Campo correto conforme estrutura da tabela
      }));

      const { error: membersError } = await dbClient
        .from('pipeline_members')
        .insert(membersData);

      if (membersError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar membros:', membersError);
      } else {
        console.log('‚úÖ [PipelineService] Membros duplicados:', membersData.length);
      }
    }

    // 7. Duplicar distribution rules
    if (originalPipeline.pipeline_distribution_rules?.length > 0) {
      const distributionData = originalPipeline.pipeline_distribution_rules.map((rule: any) => ({
        pipeline_id: newPipeline.id,
        mode: rule.mode,
        is_active: rule.is_active,
        working_hours_only: rule.working_hours_only,
        skip_inactive_members: rule.skip_inactive_members,
        fallback_to_manual: rule.fallback_to_manual,
        tenant_id: tenantId
        // N√£o copiar campos de estat√≠sticas (assignment_count, total_assignments, etc.)
        // Estes devem come√ßar zerados na nova pipeline
      }));

      const { error: distributionError } = await dbClient
        .from('pipeline_distribution_rules')
        .insert(distributionData);

      if (distributionError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar regras de distribui√ß√£o:', distributionError);
      } else {
        console.log('‚úÖ [PipelineService] Regras de distribui√ß√£o duplicadas:', distributionData.length);
      }
    }

    // 8. Duplicar cadence configs
    if (originalPipeline.cadence_configs?.length > 0) {
      const cadenceData = originalPipeline.cadence_configs.map((config: any) => ({
        pipeline_id: newPipeline.id,
        stage_name: config.stage_name,
        stage_order: config.stage_order,
        tasks: config.tasks,
        is_active: config.is_active,
        tenant_id: tenantId,
        applies_to_entire_pipeline: config.applies_to_entire_pipeline,
        pause_resume_capability: config.pause_resume_capability,
        trigger_stage: config.trigger_stage
      }));

      const { error: cadenceError } = await dbClient
        .from('cadence_configs')
        .insert(cadenceData);

      if (cadenceError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar cad√™ncias:', cadenceError);
      } else {
        console.log('‚úÖ [PipelineService] Cad√™ncias duplicadas:', cadenceData.length);
      }
    }

    console.log('‚úÖ [PipelineService] Duplica√ß√£o conclu√≠da:', {
      originalId: pipelineId,
      newId: newPipeline.id,
      newName: duplicateName
    });

    return newPipeline;
  }
} 