import { supabase } from '../config/supabase';
import { supabaseAdmin } from './supabase-admin';

export interface Pipeline {
  id: string;
  name: string;
  description: string;
  tenant_id: string;
  created_by: string;
  created_at: string;
  updated_at: string;
  pipeline_members?: any[];
  pipeline_stages?: any[];
  pipeline_custom_fields?: any[];
}

export interface CreatePipelineData {
  name: string;
  description?: string;
  tenant_id: string;
  created_by: string;
  member_ids?: string[];
}

export interface UpdatePipelineData {
  name?: string;
  description?: string;
}

export interface PipelineNameValidation {
  is_valid: boolean;
  error?: string;
  suggestion?: string;
  similar_names?: string[];
}

export class PipelineService {
  static async validatePipelineName(
    name: string, 
    tenantId: string, 
    pipelineId?: string
  ): Promise<PipelineNameValidation> {
    try {
      console.log('üîç [PipelineService] Validando nome de pipeline:', {
        name,
        tenantId,
        pipelineId: pipelineId || 'novo'
      });

      // ‚úÖ TENTAR FUN√á√ÉO POSTGRESQL PRIMEIRO (tipos corretos baseados na verifica√ß√£o)
      const { data, error } = await supabase.rpc('validate_pipeline_name_unique', {
        p_name: name.trim(),
        p_tenant_id: tenantId, // TEXT - correto conforme verifica√ß√£o
        p_pipeline_id: pipelineId || null // UUID - ser√° convertido automaticamente
      });

      if (error) {
        console.warn('‚ö†Ô∏è [PipelineService] Fun√ß√£o PostgreSQL n√£o dispon√≠vel, usando fallback:', error.message);
        throw new Error('FALLBACK_NEEDED');
      }

      console.log('‚úÖ [PipelineService] Valida√ß√£o PostgreSQL conclu√≠da:', data);

      // ‚úÖ BUSCAR PIPELINES SIMILARES MANUALMENTE
      const { data: similarPipelines } = await supabase
        .from('pipelines')
        .select('name')
        .eq('tenant_id', tenantId)
        .ilike('name', `%${name.trim()}%`)
        .limit(3);

      return {
        is_valid: data?.is_valid || false,
        error: data?.error || undefined,
        suggestion: data?.suggestion || undefined,
        similar_names: similarPipelines?.map(p => p.name) || []
      };

    } catch (error) {
      console.error('‚ùå [PipelineService] Erro cr√≠tico na valida√ß√£o:', error);
      
      const { data: existingPipelines, error: fallbackError } = await supabase
        .from('pipelines')
        .select('name')
        .eq('tenant_id', tenantId)
        .ilike('name', name.trim())
        .eq('is_active', true);

      if (fallbackError) {
        throw new Error(`Erro na valida√ß√£o fallback: ${fallbackError.message}`);
      }

      const hasConflict = existingPipelines?.some(p => 
        p.name.toLowerCase().trim() === name.toLowerCase().trim()
      ) || false;

      return {
        is_valid: !hasConflict,
        error: hasConflict ? 'J√° existe uma pipeline com este nome' : undefined,
        suggestion: hasConflict ? `${name} (2)` : undefined,
        similar_names: existingPipelines?.map(p => p.name) || []
      };
    }
  }

  static async getPipelinesByTenant(tenantId: string): Promise<Pipeline[]> {
    const { data: pipelines, error: pipelinesError } = await supabase
      .from('pipelines')
      .select('*')
      .eq('tenant_id', tenantId)
      .order('created_at', { ascending: false });

    if (pipelinesError) {
      throw new Error(`Erro ao buscar pipelines: ${pipelinesError.message}`);
    }

    if (!pipelines || pipelines.length === 0) {
      return [];
    }

    const pipelinesWithDetails = await Promise.all(
      pipelines.map(async (pipeline) => {
        const { data: pipelineMembers } = await supabase
          .from('pipeline_members')
          .select('*')
          .eq('pipeline_id', pipeline.id);

        const membersWithUserData = await Promise.all(
          (pipelineMembers || []).map(async (pm) => {
            const { data: userData } = await supabase
              .from('users')
              .select('id, first_name, last_name, email')
              .eq('id', pm.member_id)
              .single();

            return {
              ...pm,
              member: userData
            };
          })
        );

        const { data: stages } = await supabase
          .from('pipeline_stages')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('order_index');

        return {
          ...pipeline,
          pipeline_members: membersWithUserData || [],
          pipeline_stages: stages || []
        };
      })
    );

    return pipelinesWithDetails;
  }

  static async getPipelineById(id: string): Promise<Pipeline | null> {
    // üîß CORRE√á√ÉO: Buscar pipeline b√°sico primeiro
    const { data: pipeline, error } = await supabase
      .from('pipelines')
      .select('*')
      .eq('id', id)
      .single();

    if (error) {
      if (error.code === 'PGRST116') return null;
      throw new Error(`Erro ao buscar pipeline: ${error.message}`);
    }

    // üîß CORRE√á√ÉO: Buscar relacionamentos separadamente para evitar erro de schema cache
    const { data: pipelineMembers } = await supabase
      .from('pipeline_members')
      .select('*')
      .eq('pipeline_id', id);

    const { data: pipelineStages } = await supabase
      .from('pipeline_stages')
      .select('*')
      .eq('pipeline_id', id)
      .order('order_index');

    // üîß CORRE√á√ÉO: Buscar campos customizados da pipeline
    const { data: pipelineCustomFields } = await supabase
      .from('pipeline_custom_fields')
      .select('*')
      .eq('pipeline_id', id)
      .order('field_order');

    // Buscar dados dos membros se houver
    const membersWithUserData = await Promise.all(
      (pipelineMembers || []).map(async (pm) => {
        const { data: userData } = await supabase
          .from('users')
          .select('id, first_name, last_name, email')
          .eq('id', pm.member_id)
          .single();

        return {
          ...pm,
          member: userData
        };
      })
    );

    return {
      ...pipeline,
      pipeline_members: membersWithUserData,
      pipeline_stages: pipelineStages || [],
      pipeline_custom_fields: pipelineCustomFields || []
    };
  }

  static async createPipeline(data: CreatePipelineData): Promise<Pipeline> {
    const { member_ids, ...pipelineData } = data;

    console.log('üîç [PipelineService] Validando nome antes de criar pipeline...');
    const validation = await this.validatePipelineName(
      pipelineData.name,
      pipelineData.tenant_id
    );

    if (!validation.is_valid) {
      const errorMessage = `${validation.error}${validation.suggestion ? ` Sugest√£o: "${validation.suggestion}"` : ''}`;
      console.error('‚ùå [PipelineService] Valida√ß√£o falhou:', errorMessage);
      throw new Error(errorMessage);
    }

    console.log('‚úÖ [PipelineService] Nome validado, criando pipeline...');

    const { data: pipeline, error: pipelineError } = await supabase
      .from('pipelines')
      .insert(pipelineData)
      .select()
      .single();

    if (pipelineError) {
      if (pipelineError.code === '23505' && pipelineError.message.includes('idx_pipelines_unique_name_per_tenant')) {
        throw new Error(`J√° existe uma pipeline com o nome "${pipelineData.name}" nesta empresa. Escolha um nome diferente.`);
      }
      throw new Error(`Erro ao criar pipeline: ${pipelineError.message}`);
    }

    if (member_ids && member_ids.length > 0) {
      const memberInserts = member_ids.map(member_id => ({
        pipeline_id: pipeline.id,
        member_id
      }));

      const { error: membersError } = await supabase
        .from('pipeline_members')
        .insert(memberInserts);

      if (membersError) {
        console.warn('‚ö†Ô∏è [PipelineService] Erro ao adicionar membros:', membersError);
      }
    }

    console.log('‚úÖ [PipelineService] Pipeline criada com sucesso:', {
      id: pipeline.id,
      name: pipeline.name,
      tenant_id: pipeline.tenant_id
    });

    return pipeline;
  }

  static async updatePipeline(id: string, data: UpdatePipelineData): Promise<Pipeline> {
    if (data.name) {
      console.log('üîç [PipelineService] Validando novo nome para edi√ß√£o...');
      
      const currentPipeline = await this.getPipelineById(id);
      if (!currentPipeline) {
        throw new Error('Pipeline n√£o encontrada');
      }

      const validation = await this.validatePipelineName(
        data.name,
        currentPipeline.tenant_id,
        id
      );

      if (!validation.is_valid) {
        const errorMessage = `${validation.error}${validation.suggestion ? ` Sugest√£o: "${validation.suggestion}"` : ''}`;
        console.error('‚ùå [PipelineService] Valida√ß√£o de edi√ß√£o falhou:', errorMessage);
        throw new Error(errorMessage);
      }

      console.log('‚úÖ [PipelineService] Nome validado para edi√ß√£o');
    }

    const { data: pipeline, error } = await supabase
      .from('pipelines')
      .update(data)
      .eq('id', id)
      .select()
      .single();

    if (error) {
      if (error.code === '23505' && error.message.includes('idx_pipelines_unique_name_per_tenant')) {
        throw new Error(`J√° existe uma pipeline com o nome "${data.name}" nesta empresa. Escolha um nome diferente.`);
      }
      throw new Error(`Erro ao atualizar pipeline: ${error.message}`);
    }

    console.log('‚úÖ [PipelineService] Pipeline atualizada com sucesso:', {
      id: pipeline.id,
      name: pipeline.name
    });

    return pipeline;
  }

  static async deletePipeline(id: string): Promise<void> {
    const { error } = await supabase
      .from('pipelines')
      .delete()
      .eq('id', id);

    if (error) {
      throw new Error(`Erro ao excluir pipeline: ${error.message}`);
    }
  }

  static async getPipelinesByMember(memberId: string): Promise<Pipeline[]> {
    const { data: pipelineMembers, error: membersError } = await supabase
      .from('pipeline_members')
      .select('pipeline_id')
      .eq('member_id', memberId);

    if (membersError) {
      throw new Error(`Erro ao buscar pipeline_members: ${membersError.message}`);
    }

    if (!pipelineMembers || pipelineMembers.length === 0) {
      return [];
    }

    const pipelineIds = pipelineMembers.map(pm => pm.pipeline_id);

    const { data: pipelines, error: pipelinesError } = await supabase
      .from('pipelines')
      .select('*')
      .in('id', pipelineIds)
      .order('created_at', { ascending: false });

    if (pipelinesError) {
      throw new Error(`Erro ao buscar pipelines: ${pipelinesError.message}`);
    }

    if (!pipelines || pipelines.length === 0) {
      return [];
    }

    const pipelinesWithDetails = await Promise.all(
      pipelines.map(async (pipeline) => {
        const { data: stages } = await supabase
          .from('pipeline_stages')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('order_index');

        const { data: customFields } = await supabase
          .from('pipeline_custom_fields')
          .select('*')
          .eq('pipeline_id', pipeline.id)
          .order('field_order');

        return {
          ...pipeline,
          pipeline_stages: stages || [],
          pipeline_custom_fields: customFields || []
        };
      })
    );

    return pipelinesWithDetails;
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Arquivar pipeline (soft delete)
  static async archivePipeline(pipelineId: string, tenantId: string): Promise<void> {
    console.log('üìÅ [PipelineService] Arquivando pipeline:', { pipelineId, tenantId });

    // Verificar se pipeline existe e pertence ao tenant
    const { data: pipeline, error: checkError } = await supabase
      .from('pipelines')
      .select('id, name, is_active')
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId)
      .single();

    if (checkError || !pipeline) {
      throw new Error('Pipeline n√£o encontrada ou n√£o pertence a esta empresa');
    }

    if (!pipeline.is_active) {
      throw new Error('Pipeline j√° est√° inativa');
    }

    // Arquivar pipeline (soft delete)
    const { error: archiveError } = await supabase
      .from('pipelines')
      .update({ 
        is_archived: true,
        archived_at: new Date().toISOString(),
        is_active: false // Manter consist√™ncia com campo existente
      })
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId);

    if (archiveError) {
      console.error('‚ùå [PipelineService] Erro ao arquivar pipeline:', archiveError);
      throw new Error('Erro ao arquivar pipeline');
    }

    console.log('‚úÖ [PipelineService] Pipeline arquivada com sucesso:', pipeline.name);
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Desarquivar pipeline
  static async unarchivePipeline(pipelineId: string, tenantId: string): Promise<void> {
    console.log('üìÇ [PipelineService] Desarquivando pipeline:', { pipelineId, tenantId });

    // Verificar se pipeline existe e pertence ao tenant
    const { data: pipeline, error: checkError } = await supabase
      .from('pipelines')
      .select('id, name, is_archived, archived_at')
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId)
      .single();

    if (checkError || !pipeline) {
      console.error('‚ùå [PipelineService] Pipeline n√£o encontrada:', { pipelineId, tenantId, error: checkError });
      throw new Error('Pipeline n√£o encontrada ou n√£o pertence a esta empresa');
    }

    console.log('üîç [PipelineService] Status da pipeline:', { 
      id: pipeline.id, 
      name: pipeline.name, 
      is_archived: pipeline.is_archived, 
      archived_at: pipeline.archived_at 
    });

    // ‚úÖ CORRE√á√ÉO: Usar is_archived ao inv√©s de archived_at para valida√ß√£o
    if (!pipeline.is_archived) {
      console.warn('‚ö†Ô∏è [PipelineService] Pipeline j√° est√° ativa:', pipeline.name);
      throw new Error('Pipeline n√£o est√° arquivada');
    }

    // Desarquivar pipeline
    const { error: unarchiveError } = await supabase
      .from('pipelines')
      .update({ 
        is_archived: false,
        archived_at: null,
        is_active: true // Reativar pipeline
      })
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId);

    if (unarchiveError) {
      console.error('‚ùå [PipelineService] Erro ao desarquivar pipeline:', unarchiveError);
      throw new Error('Erro ao desarquivar pipeline');
    }

    console.log('‚úÖ [PipelineService] Pipeline desarquivada com sucesso:', pipeline.name);

    // ‚úÖ VALIDA√á√ÉO: Garantir que pipeline tenha etapas obrigat√≥rias ap√≥s desarquivamento
    try {
      console.log('üîç [PipelineService] Verificando etapas obrigat√≥rias ap√≥s desarquivamento...');
      // AIDEV-NOTE: Verifica√ß√£o simples de etapas - m√©todo ensurePipelineStages n√£o implementado ainda
      const { data: stages, error: stagesError } = await supabase
        .from('pipeline_stages')
        .select('id, name, stage_type')
        .eq('pipeline_id', pipelineId)
        .eq('tenant_id', tenantId);

      if (stagesError) {
        console.warn('‚ö†Ô∏è [PipelineService] Erro ao verificar etapas:', stagesError.message);
      } else if (!stages || stages.length === 0) {
        console.warn('‚ö†Ô∏è [PipelineService] Pipeline desarquivada sem etapas - pode precisar de configura√ß√£o');
      } else {
        console.log('‚úÖ [PipelineService] Etapas encontradas:', stages.length);
      }
    } catch (stageError: any) {
      console.warn('‚ö†Ô∏è [PipelineService] Aviso: Erro ao validar etapas obrigat√≥rias:', stageError.message);
      // N√£o lan√ßar erro aqui, pois pipeline j√° foi desarquivada com sucesso
      // O aviso permite que a opera√ß√£o continue, mas registra o problema
    }
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Listar pipelines arquivadas
  static async getArchivedPipelines(tenantId: string): Promise<Pipeline[]> {
    console.log('üìã [PipelineService] Buscando pipelines arquivadas para tenant:', tenantId);

    const { data: pipelines, error } = await supabase
      .from('pipelines')
      .select(`
        id, name, description, tenant_id, created_by, created_at, updated_at, archived_at,
        pipeline_stages (id, name, order_index, stage_type),
        pipeline_custom_fields (id, field_name, field_type, is_required)
      `)
      .eq('tenant_id', tenantId)
      .not('archived_at', 'is', null) // Apenas pipelines arquivadas
      .order('archived_at', { ascending: false }); // Mais recentemente arquivadas primeiro

    if (error) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipelines arquivadas:', error);
      throw new Error('Erro ao buscar pipelines arquivadas');
    }

    console.log('‚úÖ [PipelineService] Pipelines arquivadas encontradas:', pipelines?.length || 0);

    return pipelines || [];
  }

  // ‚úÖ FUNCIONALIDADE ATUALIZADA: Modificar getAllByTenant para excluir arquivadas por padr√£o
  static async getActivePipelines(tenantId: string): Promise<Pipeline[]> {
    console.log('üìã [PipelineService] Buscando pipelines ativas para tenant:', tenantId);

    const { data: pipelines, error } = await supabase
      .from('pipelines')
      .select(`
        id, name, description, tenant_id, created_by, created_at, updated_at, is_active,
        pipeline_stages (id, name, order_index, stage_type),
        pipeline_custom_fields (id, field_name, field_type, is_required)
      `)
      .eq('tenant_id', tenantId)
      .eq('is_active', true)
      .is('archived_at', null) // Apenas pipelines n√£o arquivadas
      .order('created_at', { ascending: false });

    if (error) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipelines ativas:', error);
      throw new Error('Erro ao buscar pipelines ativas');
    }

    console.log('‚úÖ [PipelineService] Pipelines ativas encontradas:', pipelines?.length || 0);

    return pipelines || [];
  }

  // ‚úÖ NOVA FUNCIONALIDADE: Duplicar pipeline completa
  static async duplicatePipeline(pipelineId: string, tenantId: string, userId: string) {
    console.log('üîÑ [PipelineService] Iniciando duplica√ß√£o:', { pipelineId, tenantId, userId });

    // 1. Buscar pipeline original com todos os dados relacionados
    const { data: originalPipeline, error: pipelineError } = await supabaseAdmin
      .from('pipelines')
      .select(`
        *,
        pipeline_stages (*),
        pipeline_custom_fields (*),
        pipeline_members (*),
        pipeline_distribution_rules (*),
        cadence_configs (*)
      `)
      .eq('id', pipelineId)
      .eq('tenant_id', tenantId)
      .single();

    if (pipelineError || !originalPipeline) {
      console.error('‚ùå [PipelineService] Erro ao buscar pipeline original:', pipelineError);
      throw new Error('Pipeline n√£o encontrada ou sem permiss√£o');
    }

    // 2. Gerar nome √∫nico para a c√≥pia
    const originalName = originalPipeline.name;
    let duplicateName = `${originalName} - C√≥pia`;
    
    // Verificar se j√° existe uma pipeline com este nome
    const { data: existingPipelines } = await supabaseAdmin
      .from('pipelines')
      .select('name')
      .eq('tenant_id', tenantId)
      .ilike('name', `${originalName}%`);
    
    // Se existir, encontrar pr√≥ximo n√∫mero dispon√≠vel
    if (existingPipelines && existingPipelines.length > 0) {
      const existingNames = existingPipelines.map(p => p.name);
      let counter = 2;
      
      while (existingNames.includes(duplicateName)) {
        duplicateName = `${originalName} (${counter})`;
        counter++;
      }
    }

    // 3. Criar nova pipeline
    const { data: newPipeline, error: newPipelineError } = await supabaseAdmin
      .from('pipelines')
      .insert({
        name: duplicateName,
        description: `${originalPipeline.description || ''} (Duplicada)`,
        tenant_id: tenantId,
        created_by: userId,
        is_active: true,
        qualification_rules: originalPipeline.qualification_rules
      })
      .select()
      .single();

    if (newPipelineError || !newPipeline) {
      console.error('‚ùå [PipelineService] Erro ao criar nova pipeline:', newPipelineError);
      throw new Error('Erro ao criar nova pipeline');
    }

    console.log('‚úÖ [PipelineService] Nova pipeline criada:', newPipeline.id);

    // 4. Duplicar stages
    if (originalPipeline.pipeline_stages?.length > 0) {
      const stagesData = originalPipeline.pipeline_stages.map((stage: any) => ({
        pipeline_id: newPipeline.id,
        name: stage.name,
        order_index: stage.order_index,
        stage_type: stage.stage_type,
        color: stage.color,
        is_default: stage.is_default,
        tenant_id: tenantId
      }));

      const { error: stagesError } = await supabaseAdmin
        .from('pipeline_stages')
        .insert(stagesData);

      if (stagesError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar stages:', stagesError);
        // N√£o falhar a opera√ß√£o, continuar
      } else {
        console.log('‚úÖ [PipelineService] Stages duplicadas:', stagesData.length);
      }
    }

    // 5. Duplicar custom fields
    if (originalPipeline.pipeline_custom_fields?.length > 0) {
      const fieldsData = originalPipeline.pipeline_custom_fields.map((field: any) => ({
        pipeline_id: newPipeline.id,
        field_name: field.field_name,
        field_label: field.field_label,
        field_type: field.field_type,
        field_options: field.field_options,
        is_required: field.is_required,
        field_order: field.field_order,
        placeholder: field.placeholder,
        show_in_card: field.show_in_card,
        tenant_id: tenantId
      }));

      const { error: fieldsError } = await supabaseAdmin
        .from('pipeline_custom_fields')
        .insert(fieldsData);

      if (fieldsError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar campos:', fieldsError);
      } else {
        console.log('‚úÖ [PipelineService] Campos customizados duplicados:', fieldsData.length);
      }
    }

    // 6. Duplicar members
    if (originalPipeline.pipeline_members?.length > 0) {
      const membersData = originalPipeline.pipeline_members.map((member: any) => ({
        pipeline_id: newPipeline.id,
        user_id: member.user_id,
        tenant_id: tenantId
      }));

      const { error: membersError } = await supabaseAdmin
        .from('pipeline_members')
        .insert(membersData);

      if (membersError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar membros:', membersError);
      } else {
        console.log('‚úÖ [PipelineService] Membros duplicados:', membersData.length);
      }
    }

    // 7. Duplicar distribution rules
    if (originalPipeline.pipeline_distribution_rules?.length > 0) {
      const distributionData = originalPipeline.pipeline_distribution_rules.map((rule: any) => ({
        pipeline_id: newPipeline.id,
        rule_type: rule.rule_type,
        rule_config: rule.rule_config,
        is_active: rule.is_active,
        tenant_id: tenantId
      }));

      const { error: distributionError } = await supabaseAdmin
        .from('pipeline_distribution_rules')
        .insert(distributionData);

      if (distributionError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar regras de distribui√ß√£o:', distributionError);
      } else {
        console.log('‚úÖ [PipelineService] Regras de distribui√ß√£o duplicadas:', distributionData.length);
      }
    }

    // 8. Duplicar cadence configs
    if (originalPipeline.cadence_configs?.length > 0) {
      const cadenceData = originalPipeline.cadence_configs.map((config: any) => ({
        pipeline_id: newPipeline.id,
        name: config.name,
        description: config.description,
        is_active: config.is_active,
        cadence_steps: config.cadence_steps,
        tenant_id: tenantId
      }));

      const { error: cadenceError } = await supabaseAdmin
        .from('cadence_configs')
        .insert(cadenceData);

      if (cadenceError) {
        console.error('‚ùå [PipelineService] Erro ao duplicar cad√™ncias:', cadenceError);
      } else {
        console.log('‚úÖ [PipelineService] Cad√™ncias duplicadas:', cadenceData.length);
      }
    }

    console.log('‚úÖ [PipelineService] Duplica√ß√£o conclu√≠da:', {
      originalId: pipelineId,
      newId: newPipeline.id,
      newName: duplicateName
    });

    return newPipeline;
  }
} 